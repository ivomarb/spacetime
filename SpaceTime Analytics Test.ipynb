{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidato:  Ivomar Brito Soares\n",
    "\n",
    "Email: ivomarbsoares@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na minha segunda experiência profissional atuei como engenheiro de pesquisa em Machine Learning (ML) num projeto que envolveu como parceiros o laboratório de inteligência artificial da Universidade Livre de Bruxelas (http//ai.vub.ac.be) e a empresa Airtopsoft SA (http://airtopsoft.com/) ambos localizados em Bruxelas na Bélgica. O objetivo desse projeto foi pesquisar e realizar um protótipo de como a técnica em ML chamada de Reinforcement Learning (RL) poderia ter sido utilizada para criar um software tipo sistema de apoio à decisão para ajudar os controladores de vôo na torre de controle dos grandes aeroportos para gerir o tráfego de aeronaves de partida. Para realizar esse projeto utilizamos o simulador de tráfego aéreo desenvolvido pela Airtopsoft denominado AirTOp. \n",
    "\n",
    "As principais tarefas que realizei nesse projeto foram as seguintes:\n",
    "<ul>\n",
    "    <li>Realizar uma extensa pesquisa bibliográfica das principais técnicas em RL: modelagem de um processo de decisão de markov, Q-learning, processos estocásticos, mecanismos de seleção de ações, aprendizagem individual e conjunta, aproximação de funções etc</li>\n",
    "    <li>Extensa revisão bibliográfica da gestão e controle de aeronaves de partida em grandes aeroportos.</li>\n",
    "    <li>Modelar usando Java e o simulador AirTOp um sistema de apoio a decisão baseado em RL. Esse processo de prototipagem durou aproximadamente um ano e meio e eu o realizei sozinho.</li>\n",
    "    <li>Realizar extensas simulações e experimentações para comparar como o módulo baseado em RL se compara com o atualmente realizado pelos controladores de vôo nos grande aeroportos. </li>\n",
    "</ul>\n",
    "Os principais objetivos alcançados com esse projeto foram os seguintes:\n",
    "<ul>\n",
    "    <li>Primeiro modelo de um processo de decisão de Markov para o contexto de gestão de aeronaves em grandes aeroportos.</li>\n",
    "    <li>Conversão do AirTOp em um simulador RL a partir do zero.</li>\n",
    "    <li>Os controladores de vôo baseados em RL tiveram melhor performance do que os controladores de vôo simulados nos cenários testados.</li>\n",
    "    <li>Um dos primeiros protótipos criado no mundo de um sistema de larga escala baseado em RL multi agentes.</li>\n",
    "    <li>Os resultados obtidos com esse projeto foram publicados numa conferência internacional: https://ieeexplore.ieee.org/document/7313285</li>\n",
    "\n",
    "</ul>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numero_ilhas(mapa):\n",
    "    \"\"\"Devolve o número de ilhas no mapa. (Considere vizinhança 4-conexa).\n",
    "    O objetivo é iterar por cada célula e se for uma ilha, realizar dfs (depth first search) para marcar\n",
    "    todas as ilhas adjacentes, e então aumentar o contador de 1.\"\"\"\n",
    "    if not mapa: return 0\n",
    "    lin, col = len(mapa), len(mapa[0])\n",
    "    visitado = [[False for _ in range(col)] for _ in range(lin)]\n",
    "\n",
    "    def dfs(i, j):\n",
    "        \"\"\"Abordage Depth first search recursiva para marcar todos os componentes de uma ilha com uma \n",
    "        vizinhança 4-conexa.\"\"\"\n",
    "        if i < 0 or i >= lin or j < 0 or j >= col or mapa[i][j] == 0 or visitado[i][j]:\n",
    "            return\n",
    "        visitado[i][j] = True\n",
    "        dfs(i + 1, j)\n",
    "        dfs(i - 1, j)\n",
    "        dfs(i, j + 1)\n",
    "        dfs(i, j - 1)\n",
    "\n",
    "    contador = 0\n",
    "    for i in range(lin):\n",
    "        for j in range(col):\n",
    "            if not visitado[i][j] and mapa[i][j] == 1:\n",
    "                dfs(i, j)\n",
    "                contador += 1\n",
    "    return contador\n",
    "\n",
    "def quantidade_de_terra_afetada(mapa, i, j):\n",
    "    '''Calcula o numero de pontos de solo do mapa que podem ser afetados por uma semente lançada em mapa[i, j] \n",
    "    (considere vizinhança 4-conexa)'''\n",
    "    \n",
    "    if mapa[i][j] == 0:\n",
    "        return 0\n",
    "    \n",
    "    lin, col = len(mapa), len(mapa[0])\n",
    "    visitado = [[False for _ in range(col)] for _ in range(lin)]\n",
    "    \n",
    "    def dfs_contador(i, j, contador):\n",
    "        \"\"\"Abordage Depth first search recursiva para calcular quantos componentes fazem parte de uma ilha afetada\n",
    "        por uma semente com uma vizinhança 4-conexa.\"\"\"\n",
    "        if i < 0 or i >= lin or j < 0 or j >= col or mapa[i][j] == 0 or visitado[i][j]:\n",
    "            return contador\n",
    "        visitado[i][j] = True\n",
    "        contador += 1\n",
    "        contador = dfs_contador(i + 1, j, contador)\n",
    "        contador = dfs_contador(i - 1, j, contador)\n",
    "        contador = dfs_contador(i, j + 1, contador)\n",
    "        contador = dfs_contador(i, j - 1, contador)\n",
    "        return contador\n",
    "    \n",
    "    if mapa[i][j] == 1:\n",
    "        return dfs_contador(i, j, 0)\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa = [[ 0., 0., 0., 0., 0., 0.],\n",
    "        [ 0., 0., 0., 0., 0., 0.],\n",
    "        [ 0., 1., 1., 1., 0., 0.],\n",
    "        [ 0., 0., 1., 0., 1., 0.],\n",
    "        [ 0., 0., 0., 0., 1., 0.],\n",
    "        [ 0., 0., 0., 0., 0., 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(numero_ilhas(mapa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(quantidade_de_terra_afetada(mapa, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(quantidade_de_terra_afetada(mapa, 2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout é uma técnica de regularização com o objetivo de reduzir overfitting em redes neurais evitando que a rede neural adote complexas adaptações no conjunto de dados de treino e não generalize bem para o conjunto de dados de teste. Nessa técnica, durante o treinamento, alguns nós da rede neural são aleatoreamente ignoradas com uma probabilidade p ou \"dropped\". Isso faz com que essa camada apareça e seja tratada com um numero diferente de nós e conectividade diferente em relação a camada anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eu trataria esse problema como um problema de regressão onde teríamos uma variável continua a ser modelada/prevista que seria a quantidade de grãos a ser colhida no ano seguinte. As features (propriedades) seriam o tamanho das espigas, cor da filha, chuvas e a variável alvo (y ou target) seria a quantidade colhida para cada talhão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eu utilizarei uma das métricas comuns para tratar modelos de regressão como o Root Mean Square Error (RMSE) que é uma métrica utilizada para medir as diferenças entre os valores previstos pelo modelo e os valores observados. Para tal, eu dividira o conjunto de dados que possuo em conjunto de treino e testes. Treinaria o modelo no conjunto de treino e avaliaria a métrica RMSE tanto no conjunto de dados como no conjunto de testes, sendo essa última utilizada para avaliar a capacidade de generalização do modelo para dados que ainda não viu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quantidade de dados exigida depende da complexidade do problema e da complexidade do algoritmo escolhido para abordá-lo. Não existe uma resposta definitiva para a quantidade de dados necessária para um modelo de predição, mas alguns indicativos ou heurísticas. Uma das primeiras abordagens é utilizar \"domain expertise\", em machine learning estamos aprendendo uma função para mapear os dados de entrada com os dados de saída, esse mapeamento so será bom o quão bom for os dados que você prover para ele, isso quer dizer que deve existir um conjunto de dados suficientes para capturar todas as relações entre as features de entrada e entre as features de entrada e de saída. Uma segunda abordagem é usar uma heurística estística, algumas dessas heurísticas podem ser: usar um fator do número das features de entrada, utilizar um fator do número de parâmetros do modelo. Uma terceira abordagem é que algoritmos não lineares exigem mais dados, se algoritmos lineares obtém boa performane com centenas de exemplos de dados por classe, pode-se ser necessário milhares de exemplos por classe ao usar um algorítimo não linear, como random forest ou uma rede neural artificial, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que pode está acontecendo é que o algoritmo está \"overfitting\" o conjunto de dados, ou seja, ele\n",
    "se ajusta demais as nuancias e aos erros do conjunto de dados e não generaliza bem quando aplicado ao conjunto de testes, ou seja, a dados que ainda não viu.\n",
    "\n",
    "Existem várias técnicas para se combater overfitting, entre elas podemos citar:\n",
    "\n",
    "<ul>\n",
    "    <li>Cross-validation: Em cross-validation usa-se o conjunto de dados iniciais para gerar múltiplas divisão de conjuntos de treino e teste. Então o algoritmo é treinado iterativamente usando todos os sub conjuntos de dados / teste criados. Isso gera um modelo que generaliza melhor para um conjunto de dados ainda não visto.</li>\n",
    "    <li>Treinar com mais dados: Não funciona todas as vezes, mas treinar com mais dados, caso ele seja limpo e relevante, pode ajudar os algoritmos a detectar o sinal melhor.</li>\n",
    "    <li>Remover algumas features: Alguns algoritmos tem um mecanismo automático de seleção de features, para aqueles que não tem, pode-se melhorar a generalização do modelo ao se remover features de entradas irrelevantes.</li>\n",
    "    <li>Parada antecipada (early stopping): Ao se treinar um algoritmo de aprendizagem iterativamente, pode-se medir o quão bem é cada iteração do modelo. Até um certo número de iterações, novas iterações melhoram o modelo. Depois desse ponto, o poder do modelo de generalizar diminui e o modelo começa a \"overfit\" o conjunto de treino. Essa técnica, consista em interromper o treinamento antes que a aprendizagem passe desse ponto.</li>\n",
    "    <li>Regularização: Regularizão (e.g, ridge, lasso etc) é um conjunto amplo de técnicas utilizadas para forçar o modelo a ser mais simples, nos modelos mais comuns, designam-se pesos a algumas features e esses pesos podem fazer que o valor das features seja zero ou algo perto disso, tornando o modelo mais simples.</li>\n",
    "    </ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
